# AI Service API Keys
# このファイルを.envにコピーして、実際のAPIキーを設定してください

# Google AI Studio API
<<<<<<< HEAD
GOOGLE_AI_API_KEY=AIzaSyC-Zheqmv6aGmaN1rDouHSCtFFH8y8VhNY
=======
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
>>>>>>> 42de7d643d987d98855d441372a3931e7de31809
GOOGLE_AI_PROJECT_ID=your_project_id_here

# OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_organization_id_here  # オプション

# Anthropic Claude API
CLAUDE_API_KEY=your_claude_api_key_here

# Local LLM Settings (LM Studio)
LM_STUDIO_API_BASE=http://localhost:1234/v1  # デフォルトのLM StudioのエンドポイントURL
LM_STUDIO_MODEL=local_model_name  # 使用するモデル名

# モデル選択設定
# 使用するAIプロバイダーを選択（google, openai, claude, local）
DEFAULT_AI_PROVIDER=google

# その他の設定
DEBUG_MODE=true
LOG_LEVEL=DEBUG

# セキュリティ設定
API_KEY_ENCRYPTION_KEY=your_encryption_key_here  # APIキーの暗号化用（オプション）

# プロキシ設定（必要な場合）
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080

# タイムアウト設定（秒）
API_TIMEOUT=30
RETRY_ATTEMPTS=3

# キャッシュ設定
ENABLE_RESPONSE_CACHE=true
CACHE_DIR=./cache
MAX_CACHE_SIZE=1000  # エントリー数

# レート制限設定
RATE_LIMIT_REQUESTS=60
RATE_LIMIT_PERIOD=60  # 秒

# モデル固有の設定
# Google AI
GOOGLE_AI_MODEL=gemini-pro  # デフォルトモデル
GOOGLE_AI_TEMPERATURE=0.7
GOOGLE_AI_MAX_TOKENS=1000

# OpenAI
OPENAI_MODEL=gpt-4  # デフォルトモデル
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# Claude
CLAUDE_MODEL=claude-3-opus-20240229  # デフォルトモデル
CLAUDE_TEMPERATURE=0.7
CLAUDE_MAX_TOKENS=2000

# LM Studio
LM_STUDIO_TEMPERATURE=0.7
LM_STUDIO_MAX_TOKENS=2000
LM_STUDIO_CONTEXT_SIZE=4096 